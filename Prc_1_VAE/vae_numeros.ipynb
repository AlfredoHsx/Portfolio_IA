{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagenes de entrenamiento: (60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load(\"numeros_data.npy\") \n",
    "X_train=X_train/255\n",
    "X_train = np.expand_dims(X_train, axis=-1).astype(np.float32)\n",
    "print(f\"Imagenes de entrenamiento: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.seed_generator = keras.random.SeedGenerator(1337)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = keras.ops.shape(z_mean)[0]\n",
    "        dim = keras.ops.shape(z_mean)[1]\n",
    "        epsilon = keras.random.normal(shape=(batch, dim), seed=self.seed_generator)\n",
    "        return z_mean + keras.ops.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\agusb\\OneDrive\\Escritorio\\ia\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">50,192</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ z_mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ z_log_var (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sampling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sampling</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ z_mean[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ z_log_var[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m320\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m18,496\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │     \u001b[38;5;34m50,192\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ z_mean (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │         \u001b[38;5;34m34\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ z_log_var (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │         \u001b[38;5;34m34\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sampling (\u001b[38;5;33mSampling\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ z_mean[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ z_log_var[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,076</span> (269.83 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m69,076\u001b[0m (269.83 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,076</span> (269.83 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m69,076\u001b[0m (269.83 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "latent_dim = 2\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = keras.layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = keras.layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = keras.layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = keras.layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"decoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"decoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)           │         \u001b[38;5;34m9,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m18,464\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │           \u001b[38;5;34m289\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,089</span> (254.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m65,089\u001b[0m (254.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,089</span> (254.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m65,089\u001b[0m (254.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = keras.layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = keras.layers.Reshape((7, 7, 64))(x)\n",
    "x = keras.layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = keras.layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = keras.layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = keras.ops.mean(\n",
    "                keras.ops.sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction),\n",
    "                    axis=(1, 2),\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - keras.ops.square(z_mean) - keras.ops.exp(z_log_var))\n",
    "            kl_loss = keras.ops.mean(keras.ops.sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - kl_loss: 1.2680 - loss: 260.0476 - reconstruction_loss: 258.7795\n",
      "Epoch 2/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - kl_loss: 4.5453 - loss: 169.8203 - reconstruction_loss: 165.2748\n",
      "Epoch 3/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 5.0174 - loss: 163.5488 - reconstruction_loss: 158.5314\n",
      "Epoch 4/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 33ms/step - kl_loss: 5.3295 - loss: 159.9566 - reconstruction_loss: 154.6271\n",
      "Epoch 5/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 74ms/step - kl_loss: 5.4091 - loss: 158.6112 - reconstruction_loss: 153.2021\n",
      "Epoch 6/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 74ms/step - kl_loss: 5.5111 - loss: 157.2088 - reconstruction_loss: 151.6977\n",
      "Epoch 7/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 74ms/step - kl_loss: 5.6075 - loss: 155.7363 - reconstruction_loss: 150.1289\n",
      "Epoch 8/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 74ms/step - kl_loss: 5.6658 - loss: 155.4108 - reconstruction_loss: 149.7450\n",
      "Epoch 9/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - kl_loss: 5.7307 - loss: 154.7348 - reconstruction_loss: 149.0041\n",
      "Epoch 10/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - kl_loss: 5.7671 - loss: 154.4763 - reconstruction_loss: 148.7092\n",
      "Epoch 11/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 40ms/step - kl_loss: 5.7661 - loss: 153.8283 - reconstruction_loss: 148.0622\n",
      "Epoch 12/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 79ms/step - kl_loss: 5.8351 - loss: 153.7697 - reconstruction_loss: 147.9346\n",
      "Epoch 13/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 82ms/step - kl_loss: 5.8668 - loss: 153.4214 - reconstruction_loss: 147.5546\n",
      "Epoch 14/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 82ms/step - kl_loss: 5.8863 - loss: 152.6798 - reconstruction_loss: 146.7935\n",
      "Epoch 15/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 79ms/step - kl_loss: 5.9129 - loss: 152.6174 - reconstruction_loss: 146.7046\n",
      "Epoch 16/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 70ms/step - kl_loss: 5.9154 - loss: 152.5081 - reconstruction_loss: 146.5927\n",
      "Epoch 17/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 55ms/step - kl_loss: 5.9837 - loss: 152.1260 - reconstruction_loss: 146.1423\n",
      "Epoch 18/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - kl_loss: 6.0019 - loss: 151.4146 - reconstruction_loss: 145.4127\n",
      "Epoch 19/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - kl_loss: 6.0153 - loss: 151.5963 - reconstruction_loss: 145.5810\n",
      "Epoch 20/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - kl_loss: 6.0167 - loss: 151.4445 - reconstruction_loss: 145.4277\n",
      "Epoch 21/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - kl_loss: 6.0271 - loss: 151.3219 - reconstruction_loss: 145.2948\n",
      "Epoch 22/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - kl_loss: 6.0526 - loss: 151.2074 - reconstruction_loss: 145.1547\n",
      "Epoch 23/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - kl_loss: 6.0650 - loss: 150.8355 - reconstruction_loss: 144.7705\n",
      "Epoch 24/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - kl_loss: 6.0751 - loss: 150.6683 - reconstruction_loss: 144.5933\n",
      "Epoch 25/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - kl_loss: 6.1005 - loss: 150.6572 - reconstruction_loss: 144.5568\n",
      "Epoch 26/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - kl_loss: 6.1325 - loss: 150.1368 - reconstruction_loss: 144.0042\n",
      "Epoch 27/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - kl_loss: 6.0960 - loss: 150.3523 - reconstruction_loss: 144.2563\n",
      "Epoch 28/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - kl_loss: 6.1223 - loss: 150.2302 - reconstruction_loss: 144.1079\n",
      "Epoch 29/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - kl_loss: 6.1478 - loss: 150.2302 - reconstruction_loss: 144.0824\n",
      "Epoch 30/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - kl_loss: 6.1247 - loss: 150.1275 - reconstruction_loss: 144.0027\n",
      "Epoch 31/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 67ms/step - kl_loss: 6.1814 - loss: 149.8667 - reconstruction_loss: 143.6853\n",
      "Epoch 32/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 81ms/step - kl_loss: 6.1856 - loss: 149.8441 - reconstruction_loss: 143.6584\n",
      "Epoch 33/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 60ms/step - kl_loss: 6.1833 - loss: 149.4059 - reconstruction_loss: 143.2226\n",
      "Epoch 34/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - kl_loss: 6.2161 - loss: 149.7483 - reconstruction_loss: 143.5321\n",
      "Epoch 35/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.1989 - loss: 149.4923 - reconstruction_loss: 143.2934\n",
      "Epoch 36/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.2274 - loss: 149.4107 - reconstruction_loss: 143.1832\n",
      "Epoch 37/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - kl_loss: 6.2356 - loss: 149.2384 - reconstruction_loss: 143.0028\n",
      "Epoch 38/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - kl_loss: 6.2456 - loss: 149.2617 - reconstruction_loss: 143.0161\n",
      "Epoch 39/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - kl_loss: 6.2486 - loss: 148.8904 - reconstruction_loss: 142.6417\n",
      "Epoch 40/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - kl_loss: 6.2647 - loss: 148.8492 - reconstruction_loss: 142.5844\n",
      "Epoch 41/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - kl_loss: 6.2660 - loss: 148.7104 - reconstruction_loss: 142.4445\n",
      "Epoch 42/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - kl_loss: 6.3127 - loss: 148.2769 - reconstruction_loss: 141.9642\n",
      "Epoch 43/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - kl_loss: 6.2987 - loss: 148.4682 - reconstruction_loss: 142.1694\n",
      "Epoch 44/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - kl_loss: 6.2966 - loss: 148.6950 - reconstruction_loss: 142.3984\n",
      "Epoch 45/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - kl_loss: 6.2980 - loss: 148.3575 - reconstruction_loss: 142.0595\n",
      "Epoch 46/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - kl_loss: 6.3209 - loss: 148.0810 - reconstruction_loss: 141.7601\n",
      "Epoch 47/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.3065 - loss: 148.0158 - reconstruction_loss: 141.7092\n",
      "Epoch 48/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.3267 - loss: 148.0934 - reconstruction_loss: 141.7667\n",
      "Epoch 49/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.3266 - loss: 148.4231 - reconstruction_loss: 142.0965\n",
      "Epoch 50/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.3382 - loss: 147.7498 - reconstruction_loss: 141.4116\n",
      "Epoch 51/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.3482 - loss: 148.2848 - reconstruction_loss: 141.9366\n",
      "Epoch 52/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.3446 - loss: 148.1009 - reconstruction_loss: 141.7563\n",
      "Epoch 53/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.3496 - loss: 147.8221 - reconstruction_loss: 141.4725\n",
      "Epoch 54/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.3725 - loss: 147.9956 - reconstruction_loss: 141.6232\n",
      "Epoch 55/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - kl_loss: 6.3733 - loss: 147.3457 - reconstruction_loss: 140.9724\n",
      "Epoch 56/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.3798 - loss: 147.5956 - reconstruction_loss: 141.2159\n",
      "Epoch 57/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.3598 - loss: 147.3314 - reconstruction_loss: 140.9716\n",
      "Epoch 58/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.3923 - loss: 147.6459 - reconstruction_loss: 141.2536\n",
      "Epoch 59/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.4221 - loss: 147.7022 - reconstruction_loss: 141.2801\n",
      "Epoch 60/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.3966 - loss: 147.4374 - reconstruction_loss: 141.0408\n",
      "Epoch 61/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.4319 - loss: 147.4125 - reconstruction_loss: 140.9807\n",
      "Epoch 62/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.4306 - loss: 147.0773 - reconstruction_loss: 140.6467\n",
      "Epoch 63/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.3977 - loss: 147.6450 - reconstruction_loss: 141.2472\n",
      "Epoch 64/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.4284 - loss: 147.1569 - reconstruction_loss: 140.7285\n",
      "Epoch 65/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.4221 - loss: 147.3508 - reconstruction_loss: 140.9287\n",
      "Epoch 66/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - kl_loss: 6.4372 - loss: 147.1132 - reconstruction_loss: 140.6760\n",
      "Epoch 67/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.4506 - loss: 147.0440 - reconstruction_loss: 140.5933\n",
      "Epoch 68/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.4679 - loss: 147.0238 - reconstruction_loss: 140.5559\n",
      "Epoch 69/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.4551 - loss: 147.0364 - reconstruction_loss: 140.5813\n",
      "Epoch 70/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - kl_loss: 6.4700 - loss: 146.9939 - reconstruction_loss: 140.5238\n",
      "Epoch 71/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.4810 - loss: 147.2562 - reconstruction_loss: 140.7751\n",
      "Epoch 72/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.4898 - loss: 146.9785 - reconstruction_loss: 140.4887\n",
      "Epoch 73/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.4674 - loss: 146.4137 - reconstruction_loss: 139.9463\n",
      "Epoch 74/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5144 - loss: 146.5138 - reconstruction_loss: 139.9995\n",
      "Epoch 75/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - kl_loss: 6.5301 - loss: 146.7811 - reconstruction_loss: 140.2510\n",
      "Epoch 76/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5078 - loss: 147.0600 - reconstruction_loss: 140.5521\n",
      "Epoch 77/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5075 - loss: 146.6282 - reconstruction_loss: 140.1206\n",
      "Epoch 78/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5049 - loss: 146.7595 - reconstruction_loss: 140.2546\n",
      "Epoch 79/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.4866 - loss: 146.4313 - reconstruction_loss: 139.9447\n",
      "Epoch 80/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5212 - loss: 146.5928 - reconstruction_loss: 140.0716\n",
      "Epoch 81/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5116 - loss: 146.4700 - reconstruction_loss: 139.9584\n",
      "Epoch 82/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5500 - loss: 146.2741 - reconstruction_loss: 139.7241\n",
      "Epoch 83/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5240 - loss: 146.3249 - reconstruction_loss: 139.8009\n",
      "Epoch 84/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - kl_loss: 6.5145 - loss: 146.4161 - reconstruction_loss: 139.9015\n",
      "Epoch 85/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5326 - loss: 146.1219 - reconstruction_loss: 139.5892\n",
      "Epoch 86/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5120 - loss: 146.3674 - reconstruction_loss: 139.8553\n",
      "Epoch 87/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5197 - loss: 146.2235 - reconstruction_loss: 139.7038\n",
      "Epoch 88/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5354 - loss: 146.2512 - reconstruction_loss: 139.7158\n",
      "Epoch 89/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5296 - loss: 145.8421 - reconstruction_loss: 139.3125\n",
      "Epoch 90/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5358 - loss: 146.1565 - reconstruction_loss: 139.6207\n",
      "Epoch 91/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5516 - loss: 145.9278 - reconstruction_loss: 139.3761\n",
      "Epoch 92/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5739 - loss: 146.1659 - reconstruction_loss: 139.5920\n",
      "Epoch 93/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5537 - loss: 145.9408 - reconstruction_loss: 139.3870\n",
      "Epoch 94/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5481 - loss: 145.8522 - reconstruction_loss: 139.3041\n",
      "Epoch 95/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5644 - loss: 145.8338 - reconstruction_loss: 139.2695\n",
      "Epoch 96/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5677 - loss: 146.1511 - reconstruction_loss: 139.5833\n",
      "Epoch 97/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5774 - loss: 146.0179 - reconstruction_loss: 139.4404\n",
      "Epoch 98/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5822 - loss: 145.6692 - reconstruction_loss: 139.0869\n",
      "Epoch 99/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5743 - loss: 146.0287 - reconstruction_loss: 139.4544\n",
      "Epoch 100/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - kl_loss: 6.5659 - loss: 145.8735 - reconstruction_loss: 139.3076\n"
     ]
    }
   ],
   "source": [
    "# Define el VAE\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "\n",
    "# Entrena el VAE\n",
    "history = vae.fit(X_train, epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_and_display_images(num_images):\n",
    "    # Generar muestras aleatorias en el espacio latente\n",
    "    latent_vectors = np.random.normal(0, 1, (num_images, 2))  # Usa un vector de 2 dimensiones para el VAE\n",
    "\n",
    "    # Generar las imágenes decodificando cada muestra\n",
    "    generated_images = vae.decoder(latent_vectors).numpy()  # Decodificar y convertir a numpy\n",
    "    \n",
    "    # Escalar las imágenes si es necesario (ajustar a 0-255)\n",
    "    generated_images = (generated_images * 127.5 + 127.5).astype(\"uint8\")  # Ajuste si está en [-1, 1]\n",
    "\n",
    "    # Configuración de la cuadrícula de visualización\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "    # Mostrar cada imagen en una subtrama\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(np.squeeze(generated_images[i]), cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Generar y mostrar 5 imágenes únicas\n",
    "generate_and_display_images(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
